{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TGvgGBbM4ms"
   },
   "source": [
    "## 신경망을 위한 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V66C7CyEhnjV"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OgDVzye6NBWf"
   },
   "outputs": [],
   "source": [
    "# 특성 생성\n",
    "\n",
    "features=np.array([[-100.1, 3240.1],\n",
    "                   [-200.2, -234.1],\n",
    "                   [5000.5, 150.1],\n",
    "                   [6000.6, -125.1],\n",
    "                   [9000.9,-673.1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "khXNADIzNzW9"
   },
   "outputs": [],
   "source": [
    "scaler=preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sspuwhDlOIZT"
   },
   "outputs": [],
   "source": [
    "features_scaled=scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 983,
     "status": "ok",
     "timestamp": 1606137406492,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "zutD9m41ORyL",
    "outputId": "992bb97a-5764-4eac-d304-3086165ad595"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.12541308,  1.96429418],\n",
       "       [-1.15329466, -0.50068741],\n",
       "       [ 0.29529406, -0.22809346],\n",
       "       [ 0.57385917, -0.42335076],\n",
       "       [ 1.40955451, -0.81216255]])"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1171,
     "status": "ok",
     "timestamp": 1606137636057,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "HmEaRkUMQDoC",
    "outputId": "105ab5f1-ab89-426e-a4c9-314d21e9cce5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 : 0.0\n",
      "표준편차 : 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "# 평균과 표준편차 출력\n",
    "print('평균 :',round(features_scaled[:,0].mean()))\n",
    "print('표준편차 :',features_scaled[:,0].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2T5zvlVQ4px"
   },
   "source": [
    "## 신경망 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EXNIyElMQ-5w"
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eFzED4otRCEc"
   },
   "outputs": [],
   "source": [
    "# 신경망 모델 생성\n",
    "\n",
    "network=models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2A_OkRJHRJej"
   },
   "outputs": [],
   "source": [
    "# 렐루 활성화 함수를 사용한 완전 연결층 추가\n",
    "\n",
    "network.add(layers.Dense(units=16, activation='relu', input_shape=(10,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DxwFUj1BRSFW"
   },
   "outputs": [],
   "source": [
    "# 렐루 활성화 함수를 사용한 완전 연결층 추가\n",
    "\n",
    "network.add(layers.Dense(units=16, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOe5bKzpRdw0"
   },
   "outputs": [],
   "source": [
    "# 시그모이드 활성화 함수를 사용한 완전 연결층 추가\n",
    "\n",
    "network.add(layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B0JfHY8VRl1j"
   },
   "outputs": [],
   "source": [
    "# 신경망의 모델 설정 완료\n",
    "\n",
    "network.compile(loss='binary_crossentropy',# 크로스 엔트로피\n",
    "                optimizer='rmsprop', #옵티마이저\n",
    "                metrics=['accuracy']) # 성능지표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPeZF-fpRxlf"
   },
   "source": [
    "#### 자주 사용하는 출력층 유형\n",
    "\n",
    "- 이진분류 : 시그모이드 함수와 하나의 유닛\n",
    "\n",
    "- 다중분류 : 소프트맥스 활성화 함수와 k개의 유닛(k는 타깃 클래스의 개수)\n",
    "\n",
    "- 회귀 : 활성화함수x, 하나의 유닛\n",
    "---\n",
    "#### 손실함수(예측값이 타깃값과 얼마나 잘 맞는지 측정하는 함수)\n",
    "\n",
    "- 이진분류 : 이진 크로스엔트로피\n",
    "\n",
    "- 다중분류 : 범주형 크로스엔트로피\n",
    "\n",
    "- 회귀 : 평균제곱오차\n",
    "---\n",
    "#### 옵티마이저 (가장 작은 손실 함수 오차를 만드는 모델 파라미터값을 찾는 전략)\n",
    "\n",
    "- 확률적 경사하강법\n",
    "\n",
    "- 모멘텀을 사용한 확률적 경사하강법\n",
    "\n",
    "- RMSProp (root mean square propagation)\n",
    "\n",
    "- Adam (adaptive moment estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 679,
     "status": "ok",
     "timestamp": 1606139587253,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "rTu4zybsXDpW",
    "outputId": "dc4afd3f-b711-4fe9-ed92-60ff79bcdf22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 16)                176       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 465\n",
      "Trainable params: 465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QuDaj8g8XEna"
   },
   "outputs": [],
   "source": [
    "## 함수형 API 사용\n",
    "\n",
    "x=layers.Input(shape=(10,))\n",
    "h1=layers.Dense(units=16, activation='relu')(x)\n",
    "h2=layers.Dense(units=16, activation='relu')(h1)\n",
    "y=layers.Dense(units=1, activation='sigmoid')(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DBrBCCbmX1tc"
   },
   "outputs": [],
   "source": [
    "# 신경망 모델 생성\n",
    "\n",
    "network=models.Model(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mOpdydgyX44p"
   },
   "outputs": [],
   "source": [
    "# 신경망의 모델 설정 완료\n",
    "\n",
    "network.compile(loss='binary_crossentropy',\n",
    "                optimizer='rmsprop',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 803,
     "status": "ok",
     "timestamp": 1606139716453,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "CHZkkEhjYFFK",
    "outputId": "f2fd606a-2919-4c0b-d0ad-3ac95fb88fb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                176       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 465\n",
      "Trainable params: 465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8d5l4GSpYGBk"
   },
   "source": [
    "## 이진 분류기 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R0NkfwUkY46j"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WqCK6q72ZA5V"
   },
   "outputs": [],
   "source": [
    "# 랜덤 시드 설정\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jmAc3K2xZi5o"
   },
   "outputs": [],
   "source": [
    "# 필요한 특성 개수 지정\n",
    "\n",
    "number_of_features=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qzrhTcf2ZmEI"
   },
   "outputs": [],
   "source": [
    "# 영화 리뷰 데이터에서 훈련 데이터와 타깃 벡터 로드\n",
    "\n",
    "(data_train, target_train),(data_test, target_test) = imdb.load_data(num_words=number_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0V9CHEyQZutg"
   },
   "outputs": [],
   "source": [
    "# 영화 리뷰 데이터를 원핫인코딩된 특성 행렬로 변환\n",
    "\n",
    "tokenizer=Tokenizer(num_words=number_of_features)\n",
    "features_train=tokenizer.sequences_to_matrix(data_train, mode='binary')\n",
    "features_test=tokenizer.sequences_to_matrix(data_test, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1MBNQ2_6Z_wt"
   },
   "outputs": [],
   "source": [
    "# 신경망 모델 생성\n",
    "\n",
    "network=models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PuWakOw2aDEg"
   },
   "outputs": [],
   "source": [
    "network.add(layers.Dense(units=16, activation='relu', input_shape=(number_of_features,)))\n",
    "network.add(layers.Dense(units=16, activation='relu'))\n",
    "network.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "network.compile(loss='binary_crossentropy',\n",
    "                optimizer='rmsprop',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4068,
     "status": "ok",
     "timestamp": 1606140310924,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "Z2RsUiGFaslM",
    "outputId": "d6ec88a1-23ca-406f-fc7a-9cd692c938df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4885 - accuracy: 0.7696 - val_loss: 0.3571 - val_accuracy: 0.8536\n",
      "Epoch 2/3\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3321 - accuracy: 0.8625 - val_loss: 0.3320 - val_accuracy: 0.8612\n",
      "Epoch 3/3\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3110 - accuracy: 0.8708 - val_loss: 0.3299 - val_accuracy: 0.8600\n"
     ]
    }
   ],
   "source": [
    "# 신경망 훈련\n",
    "\n",
    "history=network.fit(features_train, #특성\n",
    "                    target_train, #타깃벡터\n",
    "                    epochs=3, #에폭 횟수\n",
    "                    verbose=1, #에폭 과정 출력\n",
    "                    batch_size=100, #배치의 샘플 개수\n",
    "                    validation_data=(features_test, target_test)) #테스트 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1415,
     "status": "ok",
     "timestamp": 1606140407462,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "ORruHVy7bCVN",
    "outputId": "e143b980-878d-4051-cac1-ab38638bc1a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1000)"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특성 행렬 크기확인\n",
    "\n",
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3460,
     "status": "ok",
     "timestamp": 1606140550635,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "tjS_kpE6bdev",
    "outputId": "35c9df0c-34b9-448b-9432-86f0c8f3b42e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2981 - val_loss: 0.3295\n",
      "Epoch 2/3\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2823 - val_loss: 0.3374\n",
      "Epoch 3/3\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2660 - val_loss: 0.3478\n"
     ]
    }
   ],
   "source": [
    "# compile  메소드의 metrics 매개변수를 지정하지 않으면 기본적으로 손실값만 계산하여 출력한다.\n",
    "\n",
    "network.compile(loss='binary_crossentropy',\n",
    "                optimizer='rmsprop')\n",
    "\n",
    "history=network.fit(features_train,\n",
    "                    target_train,\n",
    "                    epochs=3,\n",
    "                    verbose=1,\n",
    "                    batch_size=100,\n",
    "                    validation_data=(features_test, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jAKyI-mcEiH"
   },
   "source": [
    "케라스에서 모델의 성능을 평가하는 메소드는 evaluate 이다.\n",
    "\n",
    "이 메소드도 기본적으로 compile 메소드의 metrics 매개변수에 지정한 성능 지표를 계산하여 출력한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1727,
     "status": "ok",
     "timestamp": 1606140618355,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "L5KRoHAJb8_O",
    "outputId": "fe5fbbdd-838d-42e2-a336-41673a3ca139"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.3478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34783467650413513"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.evaluate(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmqSyQ5bcN-C"
   },
   "source": [
    "## 다중 분류기 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5nrm6fRc7aj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import reuters\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import layers\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2WjottQvdKUX"
   },
   "outputs": [],
   "source": [
    "# 랜덤 시드 설정\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JEJTG2a1dLmo"
   },
   "outputs": [],
   "source": [
    "# 특성 개수 지정\n",
    "\n",
    "number_of_features=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kK4VHmMQdPw0"
   },
   "outputs": [],
   "source": [
    "# 특성, 타깃 벡터 로드\n",
    "\n",
    "data=reuters.load_data(num_words=number_of_features)\n",
    "(data_train, target_vector_train), (data_test, target_vector_test)=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VuNiK2H6dan8"
   },
   "outputs": [],
   "source": [
    "# 원핫 인코딩 변환\n",
    "\n",
    "tokenizer=Tokenizer(num_words=number_of_features)\n",
    "\n",
    "features_train=tokenizer.sequences_to_matrix(data_train, mode='binary')\n",
    "features_test=tokenizer.sequences_to_matrix(data_test, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XgFA4gUGdoLI"
   },
   "outputs": [],
   "source": [
    "# 타깃 벡터를 원핫인코딩\n",
    "\n",
    "target_train=to_categorical(target_vector_train)\n",
    "target_test=to_categorical(target_vector_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQ_CrgDAdxC5"
   },
   "outputs": [],
   "source": [
    "# 신경망 모델 생성\n",
    "\n",
    "network=models.Sequential()\n",
    "network.add(layers.Dense(units=100, activation='relu', input_shape=(number_of_features,)))\n",
    "network.add(layers.Dense(units=100, activation='relu'))\n",
    "network.add(layers.Dense(units=46, activation='softmax'))\n",
    "\n",
    "network.compile(loss='categorical_crossentropy',\n",
    "                optimizer='rmsprop',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wl8BdDNNeOsv"
   },
   "outputs": [],
   "source": [
    "# 신경망 훈련\n",
    "\n",
    "history=network.fit(features_train,\n",
    "                    target_train,\n",
    "                    epochs=3,\n",
    "                    verbose=0,\n",
    "                    batch_size=100,\n",
    "                    validation_data=(features_test, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOHLhkoHfWaJ"
   },
   "source": [
    "## 회귀 모델 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cyIgo9yKeZy1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1vNyIyXfkoM"
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1vB0rgkGfmFQ"
   },
   "outputs": [],
   "source": [
    "features, target=make_regression(n_samples=10000,\n",
    "                                 n_features=3,\n",
    "                                 n_informative=3,\n",
    "                                 n_targets=1,\n",
    "                                 noise=0.0,\n",
    "                                 random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "047tP4PFfuV0"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test=train_test_split(features, target, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c90cgS2xf_qO"
   },
   "outputs": [],
   "source": [
    "# 신경망 모델 생성\n",
    "\n",
    "network=models.Sequential()\n",
    "\n",
    "network.add(layers.Dense(units=32, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "network.add(layers.Dense(units=32, activation='relu'))\n",
    "network.add(layers.Dense(units=1))\n",
    "\n",
    "network.compile(loss='mse',\n",
    "                optimizer='RMSprop',\n",
    "                metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2459,
     "status": "ok",
     "timestamp": 1606142860410,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "PdkwipyFkaEc",
    "outputId": "6fbeea10-0945-4618-99b9-5e6f98e371c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 17328.0156 - mse: 17328.0156 - val_loss: 17702.2246 - val_mse: 17702.2246\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 16494.2559 - mse: 16494.2559 - val_loss: 16472.1875 - val_mse: 16472.1875\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 14892.5195 - mse: 14892.5195 - val_loss: 14374.2549 - val_mse: 14374.2549\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 12494.0156 - mse: 12494.0156 - val_loss: 11465.2500 - val_mse: 11465.2500\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 9351.8857 - mse: 9351.8857 - val_loss: 7931.9346 - val_mse: 7931.9346\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 5901.2661 - mse: 5901.2661 - val_loss: 4404.6421 - val_mse: 4404.6421\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2824.3113 - mse: 2824.3113 - val_loss: 1689.0649 - val_mse: 1689.0649\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 972.9689 - mse: 972.9689 - val_loss: 532.9620 - val_mse: 532.9620\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 389.1299 - mse: 389.1300 - val_loss: 296.3028 - val_mse: 296.3028\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 248.0382 - mse: 248.0382 - val_loss: 213.6617 - val_mse: 213.6617\n"
     ]
    }
   ],
   "source": [
    "history=network.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    batch_size=100,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8m7gSXsk-Kf"
   },
   "source": [
    "## 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 772,
     "status": "ok",
     "timestamp": 1606195231246,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "gHDIhINUsV9N"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import layers\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 815,
     "status": "ok",
     "timestamp": 1606195233274,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "3Bq6JgHIsepy"
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 757,
     "status": "ok",
     "timestamp": 1606195234617,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "7-KfaKMdsgBy"
   },
   "outputs": [],
   "source": [
    "number_of_features=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8811,
     "status": "ok",
     "timestamp": 1606195281540,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "bSiuzsm-skQN",
    "outputId": "32106c37-946c-4bc8-eb6a-2cc402a48e0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train,y_train), (x_test, y_test)=imdb.load_data(num_words=number_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 8757,
     "status": "ok",
     "timestamp": 1606195362088,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "fDVmFwFusqjz"
   },
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(num_words=number_of_features)\n",
    "\n",
    "features_train=tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "features_test=tokenizer.sequences_to_matrix(x_test, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 670,
     "status": "ok",
     "timestamp": 1606195456632,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "l7uHPN8CtBa_"
   },
   "outputs": [],
   "source": [
    "# 신경망 모델 생성\n",
    "\n",
    "network=models.Sequential()\n",
    "\n",
    "network.add(layers.Dense(units=16, activation='relu', input_shape=(number_of_features,)))\n",
    "network.add(layers.Dense(units=16, activation='relu'))\n",
    "network.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "network.compile(loss='binary_crossentropy',\n",
    "                optimizer='rmsprop',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10378,
     "status": "ok",
     "timestamp": 1606195541307,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "mv_6oOBAtad9",
    "outputId": "27b70e61-6ab2-4f91-b705-f22e831523bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 0.3493 - accuracy: 0.8652 - val_loss: 0.2835 - val_accuracy: 0.8857\n",
      "Epoch 2/3\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.2077 - accuracy: 0.9216 - val_loss: 0.2971 - val_accuracy: 0.8833\n",
      "Epoch 3/3\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.1715 - accuracy: 0.9358 - val_loss: 0.3280 - val_accuracy: 0.8752\n"
     ]
    }
   ],
   "source": [
    "history=network.fit(features_train,\n",
    "                    y_train,\n",
    "                    epochs=3,\n",
    "                    verbose=1,\n",
    "                    batch_size=100,\n",
    "                    validation_data=(features_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 2327,
     "status": "ok",
     "timestamp": 1606195546686,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "UIYkcXs5tsxr"
   },
   "outputs": [],
   "source": [
    "predicted_target=network.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1078,
     "status": "ok",
     "timestamp": 1606195699636,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "mHudvd09twBi",
    "outputId": "83bf96a4-a6c6-4ed3-f89b-3b2ee205aa72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.084604], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_target[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVtZiADHtyTq"
   },
   "source": [
    "## 훈련 기록 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 817,
     "status": "ok",
     "timestamp": 1606195840858,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "oXxYeC0yuuUD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 785,
     "status": "ok",
     "timestamp": 1606195845173,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "KVBmZi3gu4Pf"
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 755,
     "status": "ok",
     "timestamp": 1606195853363,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "R9mX-cK4u5Tz"
   },
   "outputs": [],
   "source": [
    "number_of_features=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 6584,
     "status": "ok",
     "timestamp": 1606195878072,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "LHH9T8mJu7UN"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test)=imdb.load_data(num_words=number_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 7746,
     "status": "ok",
     "timestamp": 1606195925037,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "GJotVvhUu_7E"
   },
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(num_words=number_of_features)\n",
    "\n",
    "features_train=tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "features_test=tokenizer.sequences_to_matrix(x_test, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 752,
     "status": "ok",
     "timestamp": 1606198013781,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "oTdDOT0avLG3",
    "outputId": "85dab2fc-fa60-4828-e3bc-abdeed1b54c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 16)                160016    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,305\n",
      "Trainable params: 160,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network=models.Sequential()\n",
    "\n",
    "network.add(layers.Dense(units=16, activation='relu', input_shape=(number_of_features,)))\n",
    "network.add(layers.Dense(units=16, activation='relu'))\n",
    "network.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1606198015007,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "_6kY8JRcvN21"
   },
   "outputs": [],
   "source": [
    "network.compile(loss='binary_crossentropy',\n",
    "                optimizer='rmsprop',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23693,
     "status": "ok",
     "timestamp": 1606198039701,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "8G-ogUoRySRo",
    "outputId": "d9eb8336-f9fb-44f4-f52c-54f6782e2d24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "25/25 [==============================] - 2s 70ms/step - loss: 0.5154 - accuracy: 0.7808 - val_loss: 0.3937 - val_accuracy: 0.8691\n",
      "Epoch 2/15\n",
      "25/25 [==============================] - 1s 56ms/step - loss: 0.3181 - accuracy: 0.8993 - val_loss: 0.3201 - val_accuracy: 0.8850\n",
      "Epoch 3/15\n",
      "25/25 [==============================] - 1s 56ms/step - loss: 0.2476 - accuracy: 0.9162 - val_loss: 0.3019 - val_accuracy: 0.8823\n",
      "Epoch 4/15\n",
      "25/25 [==============================] - 1s 56ms/step - loss: 0.2071 - accuracy: 0.9303 - val_loss: 0.2964 - val_accuracy: 0.8816\n",
      "Epoch 5/15\n",
      "25/25 [==============================] - 1s 57ms/step - loss: 0.1807 - accuracy: 0.9378 - val_loss: 0.2998 - val_accuracy: 0.8802\n",
      "Epoch 6/15\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 0.1610 - accuracy: 0.9452 - val_loss: 0.2908 - val_accuracy: 0.8836\n",
      "Epoch 7/15\n",
      "25/25 [==============================] - 1s 56ms/step - loss: 0.1439 - accuracy: 0.9514 - val_loss: 0.3059 - val_accuracy: 0.8806\n",
      "Epoch 8/15\n",
      "25/25 [==============================] - 1s 56ms/step - loss: 0.1322 - accuracy: 0.9557 - val_loss: 0.3160 - val_accuracy: 0.8775\n",
      "Epoch 9/15\n",
      "25/25 [==============================] - 1s 57ms/step - loss: 0.1216 - accuracy: 0.9586 - val_loss: 0.4075 - val_accuracy: 0.8542\n",
      "Epoch 10/15\n",
      "25/25 [==============================] - 1s 56ms/step - loss: 0.1051 - accuracy: 0.9671 - val_loss: 0.3518 - val_accuracy: 0.8721\n",
      "Epoch 11/15\n",
      "25/25 [==============================] - 1s 56ms/step - loss: 0.0984 - accuracy: 0.9685 - val_loss: 0.4072 - val_accuracy: 0.8603\n",
      "Epoch 12/15\n",
      "25/25 [==============================] - 1s 56ms/step - loss: 0.0965 - accuracy: 0.9679 - val_loss: 0.3858 - val_accuracy: 0.8668\n",
      "Epoch 13/15\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.0844 - accuracy: 0.9734 - val_loss: 0.3903 - val_accuracy: 0.8678\n",
      "Epoch 14/15\n",
      "25/25 [==============================] - 1s 56ms/step - loss: 0.0787 - accuracy: 0.9743 - val_loss: 0.4084 - val_accuracy: 0.8661\n",
      "Epoch 15/15\n",
      "25/25 [==============================] - 1s 56ms/step - loss: 0.0732 - accuracy: 0.9764 - val_loss: 0.4533 - val_accuracy: 0.8597\n"
     ]
    }
   ],
   "source": [
    "history=network.fit(features_train,\n",
    "                    y_train,\n",
    "                    epochs=15,\n",
    "                    verbose=1,\n",
    "                    batch_size=1000,\n",
    "                    validation_data=(features_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 998,
     "status": "ok",
     "timestamp": 1606198042741,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "ltOU1hvnzKlM"
   },
   "outputs": [],
   "source": [
    "# 훈련손실과 테스트 손실의 기록 저장\n",
    "\n",
    "training_loss=history.history['loss']\n",
    "test_loss=history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 500,
     "status": "ok",
     "timestamp": 1606198043206,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "RTC8soynzeMD"
   },
   "outputs": [],
   "source": [
    "# 에폭 횟수를 사용해 카운트 객체 생성\n",
    "\n",
    "epoch_count=range(1, len(training_loss)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 923,
     "status": "ok",
     "timestamp": 1606198044732,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "cZXmA2HKznXi",
    "outputId": "c31de3f3-ed44-40f8-a392-09d23326730f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 손실값의 기록 시각화\n",
    "\n",
    "plt.plot(epoch_count, training_loss, \"r--\")\n",
    "plt.plot(epoch_count, test_loss, \"b-\")\n",
    "plt.legend(['Training Loss','Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 940,
     "status": "ok",
     "timestamp": 1606198231353,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "5Qmd-5bI24uZ",
    "outputId": "45e2d602-ba6b-4886-ef1f-ea4f0cbd18f8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 훈련 정확도와 테스트 정확도 기록 저장\n",
    "\n",
    "training_accuracy=history.history['accuracy']\n",
    "test_accuracy=history.history['val_accuracy']\n",
    "plt.plot(epoch_count, training_accuracy, 'r--')\n",
    "plt.plot(epoch_count, test_accuracy,'b-')\n",
    "\n",
    "plt.legend(['Training Accuracy','Test Accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJDmAuV54VR3"
   },
   "source": [
    "## 가중치 규제로 과대적합 줄이기\n",
    "#### 네트워크 모델 파라미터에 제한을 가한다 -> 가중치 규제 (Weight Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 636,
     "status": "ok",
     "timestamp": 1606199400466,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "YwiCxVTk4cp2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 840,
     "status": "ok",
     "timestamp": 1606199406522,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "9x399OWn8dUa"
   },
   "outputs": [],
   "source": [
    "number_of_features=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 6983,
     "status": "ok",
     "timestamp": 1606199429483,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "w5a3qMAU8ewx"
   },
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)=imdb.load_data(num_words=number_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 5056,
     "status": "ok",
     "timestamp": 1606199463226,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "irTHpuZ58i3s"
   },
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(num_words=number_of_features)\n",
    "\n",
    "features_train=tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "features_test=tokenizer.sequences_to_matrix(x_test, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 834,
     "status": "ok",
     "timestamp": 1606199888123,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "DwPezEk58rj9"
   },
   "outputs": [],
   "source": [
    "network=models.Sequential()\n",
    "\n",
    "network.add(layers.Dense(units=16, activation='relu', kernel_regularizer='l1_l2',input_shape=(number_of_features,)))\n",
    "network.add(layers.Dense(units=16, activation='relu'))\n",
    "network.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "network.compile(loss='binary_crossentropy',\n",
    "                optimizer='rmsprop',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "executionInfo": {
     "elapsed": 15861,
     "status": "ok",
     "timestamp": 1606199904610,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "WLB2WiYn9INg"
   },
   "outputs": [],
   "source": [
    "history=network.fit(features_train,\n",
    "                    y_train,\n",
    "                    epochs=20,\n",
    "                    verbose=0,\n",
    "                    batch_size=100,\n",
    "                    validation_data=(features_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kl-rvqC_IVz"
   },
   "source": [
    "## 조기종료로 과대적합 줄이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "executionInfo": {
     "elapsed": 773,
     "status": "ok",
     "timestamp": 1606200258648,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "AgIijFlf_P8R"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "executionInfo": {
     "elapsed": 845,
     "status": "ok",
     "timestamp": 1606200263537,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "DlobP7Ly_usK"
   },
   "outputs": [],
   "source": [
    "number_of_features=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "executionInfo": {
     "elapsed": 6694,
     "status": "ok",
     "timestamp": 1606200288620,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "4AIgs56y_v_v"
   },
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)=imdb.load_data(num_words=number_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "executionInfo": {
     "elapsed": 4779,
     "status": "ok",
     "timestamp": 1606200326571,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "VEIOR18d_0sS"
   },
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(num_words=number_of_features)\n",
    "features_train=tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "features_test=tokenizer.sequences_to_matrix(x_test, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "executionInfo": {
     "elapsed": 958,
     "status": "ok",
     "timestamp": 1606200414154,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "YNQ3OdVS_-bK"
   },
   "outputs": [],
   "source": [
    "network=models.Sequential()\n",
    "\n",
    "network.add(layers.Dense(units=16, activation='relu', input_shape=(number_of_features,)))\n",
    "network.add(layers.Dense(units=16, activation='relu'))\n",
    "network.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "network.compile(loss='binary_crossentropy',\n",
    "                optimizer='rmsprop',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "executionInfo": {
     "elapsed": 731,
     "status": "ok",
     "timestamp": 1606200475508,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "q2LCC1mcAUux"
   },
   "outputs": [],
   "source": [
    "# 훈련을 조기종료하고 최선의 모델을 저장하기 위해 콜백 함수를 설정\n",
    "\n",
    "callbacks=[EarlyStopping(monitor='val_loss', patience=2), # 연속적으로 2 에폭동안 테스트 손실이 향상되지 않으면 훈련을 멈추도록 설정,  patience=2 로 설정했기 대문에, 최선의 모델은 아니지만 최적 지점에서 2 에폭 지난 모델을 얻음\n",
    "           ModelCheckpoint(filepath='best_model.h5',\n",
    "                           monitor='val_loss',\n",
    "                           save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "executionInfo": {
     "elapsed": 5607,
     "status": "ok",
     "timestamp": 1606200515614,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "zl8pLZLSAjwt"
   },
   "outputs": [],
   "source": [
    "history=network.fit(features_train,\n",
    "                    y_train,\n",
    "                    epochs=20,\n",
    "                    verbose=0,\n",
    "                    callbacks=callbacks,\n",
    "                    batch_size=100,\n",
    "                    validation_data=(features_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7RRiMkyAsX9"
   },
   "source": [
    "## 드롭아웃으로 과대적합 줄이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "executionInfo": {
     "elapsed": 1025,
     "status": "ok",
     "timestamp": 1606200825023,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "5MUtvUDYBuAc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import layers\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "executionInfo": {
     "elapsed": 856,
     "status": "ok",
     "timestamp": 1606200827989,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "fN2Up01tB5B6"
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "executionInfo": {
     "elapsed": 718,
     "status": "ok",
     "timestamp": 1606200833299,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "BBGZFRNAB5te"
   },
   "outputs": [],
   "source": [
    "number_of_features=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "executionInfo": {
     "elapsed": 11089,
     "status": "ok",
     "timestamp": 1606200908497,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "ze-f9WNRB7IT"
   },
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)=imdb.load_data(num_words=number_of_features)\n",
    "\n",
    "tokenizer=Tokenizer(num_words=number_of_features)\n",
    "features_train=tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "features_test=tokenizer.sequences_to_matrix(x_test, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "executionInfo": {
     "elapsed": 730,
     "status": "ok",
     "timestamp": 1606201007976,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "BEttpFIOCK9A"
   },
   "outputs": [],
   "source": [
    "network=models.Sequential()\n",
    "\n",
    "network.add(layers.Dropout(0.2, input_shape=(number_of_features,)))\n",
    "network.add(layers.Dense(units=16, activation='relu'))\n",
    "network.add(layers.Dropout(0.5))\n",
    "network.add(layers.Dense(units=16,activation='relu'))\n",
    "network.add(layers.Dropout(0.5))\n",
    "network.add(layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "executionInfo": {
     "elapsed": 785,
     "status": "ok",
     "timestamp": 1606201036790,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "H-Q1rfpYCiGK"
   },
   "outputs": [],
   "source": [
    "network.compile(loss='binary_crossentropy',\n",
    "                optimizer='rmsprop',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4799,
     "status": "ok",
     "timestamp": 1606201073858,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "J7Wuh2rvCsyf",
    "outputId": "733a0f34-cd35-4f32-ac0f-2ef1d66247c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.6368 - accuracy: 0.6219 - val_loss: 0.4728 - val_accuracy: 0.8229\n",
      "Epoch 2/3\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.5002 - accuracy: 0.7629 - val_loss: 0.3770 - val_accuracy: 0.8494\n",
      "Epoch 3/3\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4528 - accuracy: 0.7985 - val_loss: 0.3532 - val_accuracy: 0.8521\n"
     ]
    }
   ],
   "source": [
    "history=network.fit(features_train,\n",
    "                    y_train,\n",
    "                    epochs=3,\n",
    "                    verbose=1,\n",
    "                    batch_size=100,\n",
    "                    validation_data=(features_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98pDH8MwC0vU"
   },
   "source": [
    "## 모델 훈련 진행 과정을 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "executionInfo": {
     "elapsed": 973,
     "status": "ok",
     "timestamp": 1606201281569,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "jH_NsGwlDLYu"
   },
   "outputs": [],
   "source": [
    "network=models.Sequential()\n",
    "\n",
    "network.add(layers.Dense(units=16, activation='relu', input_shape=(1000,)))\n",
    "network.add(layers.Dense(units=16, activation='relu'))\n",
    "network.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "network.compile(loss='binary_crossentropy',\n",
    "                optimizer='rmsprop',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "executionInfo": {
     "elapsed": 771,
     "status": "ok",
     "timestamp": 1606201357309,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "Xd-Ll72RDogM"
   },
   "outputs": [],
   "source": [
    "# 훈련을 조기 종료하고 최선의 모델을저장하기 위해 콜백 함수를 설정\n",
    "\n",
    "checkpoint=[ModelCheckpoint(filepath='models.hdf5')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "executionInfo": {
     "elapsed": 3812,
     "status": "ok",
     "timestamp": 1606201405454,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "wPo1iJH6D7C8"
   },
   "outputs": [],
   "source": [
    "history=network.fit(features_train,\n",
    "                    y_train,\n",
    "                    epochs=3,\n",
    "                    verbose=0,\n",
    "                    callbacks=checkpoint,\n",
    "                    batch_size=100,\n",
    "                    validation_data=(features_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dsPP1cNEGDt"
   },
   "source": [
    "파일이름에 에폭 횟수와 테스트 손실 점수를 포함시키는 방법\n",
    "\n",
    "filepath='model_{epoch:02d}_{val_loss:.2f}.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6prMmjuUETdo"
   },
   "source": [
    "## 신경망을 k-폴드 교차검증하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "executionInfo": {
     "elapsed": 861,
     "status": "ok",
     "timestamp": 1606201884766,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "sG4A-L-sETsP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "np.random.seed(0)\n",
    "number_of_features=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "executionInfo": {
     "elapsed": 740,
     "status": "ok",
     "timestamp": 1606201945012,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "6J5FrvZUF7yS"
   },
   "outputs": [],
   "source": [
    "features, target=make_classification(n_samples=10000,\n",
    "                                     n_features=number_of_features,\n",
    "                                     n_informative=3,\n",
    "                                     n_redundant=0,\n",
    "                                     n_classes=2,\n",
    "                                     weights=[.5,.5],\n",
    "                                     random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "executionInfo": {
     "elapsed": 716,
     "status": "ok",
     "timestamp": 1606202052474,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "2O9AfVuqGKh6"
   },
   "outputs": [],
   "source": [
    "# 설정 완료된 신경망을 반환하는 함수 생성\n",
    "\n",
    "def create_network():\n",
    "  network=models.Sequential()\n",
    "  network.add(layers.Dense(units=16, activation='relu', input_shape=(number_of_features,)))\n",
    "  network.add(layers.Dense(units=16, activation='relu'))\n",
    "  network.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "  network.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "  \n",
    "  return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "executionInfo": {
     "elapsed": 898,
     "status": "ok",
     "timestamp": 1606202086154,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "aIi6hXM-Gkxx"
   },
   "outputs": [],
   "source": [
    "# 케라스 모델을 래핑하여 사이킷런에서 사용할수 있도록 변환\n",
    "\n",
    "neural_network=KerasClassifier(build_fn=create_network,\n",
    "                               epochs=10,\n",
    "                               batch_size=100,\n",
    "                               verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5840,
     "status": "ok",
     "timestamp": 1606202115247,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "7hwHhH3qGs9D",
    "outputId": "7768a68d-35e6-4a54-a476-c0cfbb973bb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85932815, 0.81068105, 0.86738676])"
      ]
     },
     "execution_count": 96,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3-폴드 교차검증을 사용하여 신경망 평가\n",
    "\n",
    "cross_val_score(neural_network, features, target, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuKn_yosGy2h"
   },
   "source": [
    "## 신경망 튜닝하기\n",
    "#### 신경망을 위해 가장 좋은 하이퍼파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "executionInfo": {
     "elapsed": 940,
     "status": "ok",
     "timestamp": 1606202311226,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "Exq1XTCoHOfv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "executionInfo": {
     "elapsed": 696,
     "status": "ok",
     "timestamp": 1606202419749,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "tOfjfBp8HeOk"
   },
   "outputs": [],
   "source": [
    "# 설정 완료된 신경망을 반환하는 함수 생성\n",
    "\n",
    "def create_network(optimizer='rmsprop'):\n",
    "  network=models.Sequential()\n",
    "\n",
    "  network.add(layers.Dense(units=16, activation='relu', input_shape=(100,)))\n",
    "  network.add(layers.Dense(units=16, activation='relu'))\n",
    "  network.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "  network.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "  \n",
    "  return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "executionInfo": {
     "elapsed": 1009,
     "status": "ok",
     "timestamp": 1606202440127,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "j1yC5PbjH-b_"
   },
   "outputs": [],
   "source": [
    "neural_network=KerasClassifier(build_fn=create_network, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "executionInfo": {
     "elapsed": 706,
     "status": "ok",
     "timestamp": 1606202472857,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "fBUX5iAQIDWK"
   },
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 탐색 영역 정의\n",
    "\n",
    "epochs=[5,10]\n",
    "batches=[5,10,100]\n",
    "optimizers=['rmsprop','adam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "executionInfo": {
     "elapsed": 661,
     "status": "ok",
     "timestamp": 1606202508882,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "1Gzhtb94ILaX"
   },
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 그리드 생성\n",
    "\n",
    "hyperparameters=dict(optimizer=optimizers, epochs=epochs, batch_size=batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "executionInfo": {
     "elapsed": 759,
     "status": "ok",
     "timestamp": 1606202543723,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "gNatSUEiIUM7"
   },
   "outputs": [],
   "source": [
    "# 그리드 서치 생성\n",
    "\n",
    "grid=GridSearchCV(estimator=neural_network, param_grid=hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "executionInfo": {
     "elapsed": 385698,
     "status": "ok",
     "timestamp": 1606202939204,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "STOqe3I6IaDH"
   },
   "outputs": [],
   "source": [
    "# 그리드 서치 수행\n",
    "\n",
    "gird_result=grid.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1109,
     "status": "ok",
     "timestamp": 1606205200857,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "MN3-q7sxIfQf",
    "outputId": "bcd48b07-d54f-4a9e-9080-2b6b68dd6474"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 10, 'epochs': 5, 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 106,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gird_result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oAOVXBsHJFmu"
   },
   "source": [
    "## 신경망 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "executionInfo": {
     "elapsed": 779,
     "status": "ok",
     "timestamp": 1606205213989,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "ygk8S2LzJIgE"
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "executionInfo": {
     "elapsed": 895,
     "status": "ok",
     "timestamp": 1606205222543,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "50xgVwNbJUao"
   },
   "outputs": [],
   "source": [
    "network=models.Sequential()\n",
    "network.add(layers.Dense(units=16, activation='relu', input_shape=(10,)))\n",
    "network.add(layers.Dense(units=16, activation='relu'))\n",
    "network.add(layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "executionInfo": {
     "elapsed": 734,
     "status": "ok",
     "timestamp": 1606205244051,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "RfxFgLX2JVDg",
    "outputId": "db849ca5-f66a-48b6-ed98-0399b44b3f2f"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"405pt\" viewBox=\"0.00 0.00 317.00 304.00\" width=\"423pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 300)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-300 313,-300 313,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140413814877712 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140413814877712</title>\n",
       "<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 309,-295.5 309,-249.5 0,-249.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94\" y=\"-268.8\">dense_222_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"188,-249.5 188,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"188,-272.5 246,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"246,-249.5 246,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-280.3\">[(?, 10)]</text>\n",
       "<polyline fill=\"none\" points=\"246,-272.5 309,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-257.3\">[(?, 10)]</text>\n",
       "</g>\n",
       "<!-- 140413814875976 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140413814875976</title>\n",
       "<polygon fill=\"none\" points=\"37.5,-166.5 37.5,-212.5 271.5,-212.5 271.5,-166.5 37.5,-166.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.5\" y=\"-185.8\">dense_222: Dense</text>\n",
       "<polyline fill=\"none\" points=\"159.5,-166.5 159.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"159.5,-189.5 217.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"217.5,-166.5 217.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244.5\" y=\"-197.3\">(?, 10)</text>\n",
       "<polyline fill=\"none\" points=\"217.5,-189.5 271.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244.5\" y=\"-174.3\">(?, 16)</text>\n",
       "</g>\n",
       "<!-- 140413814877712&#45;&gt;140413814875976 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140413814877712-&gt;140413814875976</title>\n",
       "<path d=\"M154.5,-249.3799C154.5,-241.1745 154.5,-231.7679 154.5,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"158.0001,-222.784 154.5,-212.784 151.0001,-222.784 158.0001,-222.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140413206189448 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140413206189448</title>\n",
       "<polygon fill=\"none\" points=\"37.5,-83.5 37.5,-129.5 271.5,-129.5 271.5,-83.5 37.5,-83.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.5\" y=\"-102.8\">dense_223: Dense</text>\n",
       "<polyline fill=\"none\" points=\"159.5,-83.5 159.5,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"159.5,-106.5 217.5,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"217.5,-83.5 217.5,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244.5\" y=\"-114.3\">(?, 16)</text>\n",
       "<polyline fill=\"none\" points=\"217.5,-106.5 271.5,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244.5\" y=\"-91.3\">(?, 16)</text>\n",
       "</g>\n",
       "<!-- 140413814875976&#45;&gt;140413206189448 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140413814875976-&gt;140413206189448</title>\n",
       "<path d=\"M154.5,-166.3799C154.5,-158.1745 154.5,-148.7679 154.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"158.0001,-139.784 154.5,-129.784 151.0001,-139.784 158.0001,-139.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140413814876256 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140413814876256</title>\n",
       "<polygon fill=\"none\" points=\"37.5,-.5 37.5,-46.5 271.5,-46.5 271.5,-.5 37.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.5\" y=\"-19.8\">dense_224: Dense</text>\n",
       "<polyline fill=\"none\" points=\"159.5,-.5 159.5,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"159.5,-23.5 217.5,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"217.5,-.5 217.5,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244.5\" y=\"-31.3\">(?, 16)</text>\n",
       "<polyline fill=\"none\" points=\"217.5,-23.5 271.5,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244.5\" y=\"-8.3\">(?, 1)</text>\n",
       "</g>\n",
       "<!-- 140413206189448&#45;&gt;140413814876256 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140413206189448-&gt;140413814876256</title>\n",
       "<path d=\"M154.5,-83.3799C154.5,-75.1745 154.5,-65.7679 154.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"158.0001,-56.784 154.5,-46.784 151.0001,-56.784 158.0001,-56.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 111,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(network, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "executionInfo": {
     "elapsed": 971,
     "status": "ok",
     "timestamp": 1606205271535,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "z0Ra4aMxJVMy",
    "outputId": "e8be1b2f-0385-43a6-8ef8-38fa187220ff"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 112,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 신경망 구조를 시각화한 그림을 저장하는법\n",
    "\n",
    "plot_model(network, show_shapes=True, to_file='network.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "executionInfo": {
     "elapsed": 1125,
     "status": "ok",
     "timestamp": 1606206343081,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "L2Gpdl_3JVUu",
    "outputId": "086189a2-120e-4036-ad7d-e47598890717"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"352pt\" viewBox=\"0.00 0.00 196.00 264.00\" width=\"261pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 260)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-260 192,-260 192,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140413814877712 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140413814877712</title>\n",
       "<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 188,-255.5 188,-219.5 0,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94\" y=\"-233.8\">dense_222_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140413814875976 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140413814875976</title>\n",
       "<polygon fill=\"none\" points=\"33,-146.5 33,-182.5 155,-182.5 155,-146.5 33,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94\" y=\"-160.8\">dense_222: Dense</text>\n",
       "</g>\n",
       "<!-- 140413814877712&#45;&gt;140413814875976 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140413814877712-&gt;140413814875976</title>\n",
       "<path d=\"M94,-219.4551C94,-211.3828 94,-201.6764 94,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"97.5001,-192.5903 94,-182.5904 90.5001,-192.5904 97.5001,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140413206189448 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140413206189448</title>\n",
       "<polygon fill=\"none\" points=\"33,-73.5 33,-109.5 155,-109.5 155,-73.5 33,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94\" y=\"-87.8\">dense_223: Dense</text>\n",
       "</g>\n",
       "<!-- 140413814875976&#45;&gt;140413206189448 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140413814875976-&gt;140413206189448</title>\n",
       "<path d=\"M94,-146.4551C94,-138.3828 94,-128.6764 94,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"97.5001,-119.5903 94,-109.5904 90.5001,-119.5904 97.5001,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140413814876256 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140413814876256</title>\n",
       "<polygon fill=\"none\" points=\"33,-.5 33,-36.5 155,-36.5 155,-.5 33,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94\" y=\"-14.8\">dense_224: Dense</text>\n",
       "</g>\n",
       "<!-- 140413206189448&#45;&gt;140413814876256 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140413206189448-&gt;140413814876256</title>\n",
       "<path d=\"M94,-73.4551C94,-65.3828 94,-55.6764 94,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"97.5001,-46.5903 94,-36.5904 90.5001,-46.5904 97.5001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 113,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(network, show_shapes=False).create(prog='dot',format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "executionInfo": {
     "elapsed": 754,
     "status": "ok",
     "timestamp": 1606206363914,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "8bM9Pm3YW8Ln",
    "outputId": "b4b59f7a-30ed-43a0-e68e-0e5dc34b27c2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 114,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(network, show_shapes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFGIBdEjXBWM"
   },
   "source": [
    "## 이미지 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2409,
     "status": "ok",
     "timestamp": 1606220586522,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "Fsog-lLvXD9d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 645,
     "status": "ok",
     "timestamp": 1606220587969,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "Z5pDe-nuYLBw"
   },
   "outputs": [],
   "source": [
    "# 컬러 채널이 처음에 오도록 설정\n",
    "\n",
    "K.set_image_data_format(\"channels_first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 535,
     "status": "ok",
     "timestamp": 1606220589202,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "9qdhVdyfYPvq"
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 422,
     "status": "ok",
     "timestamp": 1606220590309,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "zfjU0QrBYQqS"
   },
   "outputs": [],
   "source": [
    "#이미지 정보 설정\n",
    "\n",
    "channels=1\n",
    "height=28\n",
    "width=28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 990,
     "status": "ok",
     "timestamp": 1606220592342,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "xZ3gxHQzYULj",
    "outputId": "088fecb8-f0f6-4b4b-cd75-d8bd8ab9becf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# MNIST 데이터에서 훈련 데이터와 타깃 데이터 로드\n",
    "\n",
    "(x_train, y_train), (x_test, y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 554,
     "status": "ok",
     "timestamp": 1606220593105,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "soft2pTlYbCj"
   },
   "outputs": [],
   "source": [
    "# 훈련 이미지 데이터를 특성의 크기로 변경\n",
    "\n",
    "x_train=x_train.reshape(x_train.shape[0],channels,height,width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 662,
     "status": "ok",
     "timestamp": 1606220594631,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "d6GETuSnYiDx"
   },
   "outputs": [],
   "source": [
    "x_test=x_test.reshape(x_test.shape[0],channels, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 735,
     "status": "ok",
     "timestamp": 1606220596022,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "Nql0l38JYlQ6"
   },
   "outputs": [],
   "source": [
    "# 0과 1 사이로 픽셀 강도의 스케일 조정\n",
    "\n",
    "features_train=x_train/255\n",
    "features_test=x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 664,
     "status": "ok",
     "timestamp": 1606220597278,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "IoNUFhNUY1ws"
   },
   "outputs": [],
   "source": [
    "# 타깃 데이터 원핫 인코딩\n",
    "\n",
    "target_train=np_utils.to_categorical(y_train)\n",
    "target_test=np_utils.to_categorical(y_test)\n",
    "\n",
    "number_of_classes=target_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1000,
     "status": "ok",
     "timestamp": 1606220598963,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "8XzKlv9rY_8r"
   },
   "outputs": [],
   "source": [
    "# 신경망 모델 생성\n",
    "network=Sequential()\n",
    "\n",
    "# 64필터, 5x5 윈도, 렐루 활성화 함수를 사용하는 합성곱층 생성\n",
    "network.add(Conv2D(filters=64, kernel_size=(5,5), input_shape=(channels, width, height), activation='relu'))\n",
    "\n",
    "# 2x2 윈도를 사용하는 최대 풀링층 추가\n",
    "network.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# 드롭아웃층 추가\n",
    "network.add(Dropout(0.5))\n",
    "\n",
    "# 입력을 일려로 펼치기 위한 층 추가\n",
    "network.add(Flatten())\n",
    "\n",
    "# 렐루 활성화 함수를 사용한 128개의 유닛 완전 연결층 추가\n",
    "network.add(Dense(128, activation='relu'))\n",
    "\n",
    "# 드롭아웃층 추가\n",
    "network.add(Dropout(0.5))\n",
    "\n",
    "# 소프트맥스 활성화 함수를 사용하는 완전 연결층 추가\n",
    "network.add(Dense(number_of_classes, activation='softmax'))\n",
    "\n",
    "# 신경망의 모델 설정 완료\n",
    "network.compile(loss='categorical_crossentropy',\n",
    "                optimizer='rmsprop',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 1899,
     "status": "error",
     "timestamp": 1606220602313,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "x8I5w320bxY3",
    "outputId": "55f3d413-f5b9-4748-a85b-3d91bf5694c7"
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-fed9c6c241c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             validation_data=(features_test, target_test))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Default MaxPoolingOp only supports NHWC on device type CPU\n\t [[node sequential/max_pooling2d/MaxPool (defined at <ipython-input-11-fed9c6c241c1>:8) ]] [Op:__inference_train_function_864]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "# 신경망 훈련\n",
    "\n",
    "network.fit(features_train,\n",
    "            target_train,\n",
    "            epochs=2,\n",
    "            verbose=0,\n",
    "            batch_size=1000,\n",
    "            validation_data=(features_test, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QFPQ9q5b5yE"
   },
   "source": [
    "## 이미지 증식으로 성능 향상하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 960,
     "status": "ok",
     "timestamp": 1606220750969,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "ZoTgoDU2N1nu"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 653,
     "status": "ok",
     "timestamp": 1606220832500,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "ZvqGFETiN5xs"
   },
   "outputs": [],
   "source": [
    "# 이미지 증식을 위해 객체 생성\n",
    "\n",
    "augmentation=ImageDataGenerator(featurewise_center=True, # ZCA 화이트닝 적용\n",
    "                                zoom_range=0.3, # 이미지를 랜덤하게 확대\n",
    "                                width_shift_range=0.2, # 이미지를 랜덤하게 이동\n",
    "                                horizontal_flip=True, # 이미지를 랜덤하게 뒤집기\n",
    "                                rotation_range=90) # 랜덤하게 회전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FjH4obQmONu4"
   },
   "outputs": [],
   "source": [
    "augmentation_images=augmentation.flow_from_directory('raw/images', # 이미지가 담긴 폴더\n",
    "                                                     batch_size=32, # 배치크기\n",
    "                                                     class_mode='binary',\n",
    "                                                     save_to_dir='processed/images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4vcaQUcOhQ1"
   },
   "source": [
    "augmentation_images 는 제너레이터 이기 때문에 신경망을 훈련할때 fit 메소드 대신\n",
    "\n",
    "fit_generator 메소드를 사용해야 한다. 예를 들어 아래와 같다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2HoiFIVwO4fJ"
   },
   "outputs": [],
   "source": [
    "network.fit_generator(augmentation_images,\n",
    "                      #에폭마다 제너레이터를 호출할 횟수\n",
    "                      steps_per_epoch=2000,\n",
    "                      epochs=5,\n",
    "                      # 테스트 데이터 제너레이터\n",
    "                      validation_data=augment_images_test,\n",
    "                      # 테스트 에폭마다 제너레이터를 호출할 횟수\n",
    "                      validation_steps=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTFesbPIPJki"
   },
   "source": [
    "## 텍스트 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 729,
     "status": "ok",
     "timestamp": 1606221126010,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "qDJp_ye_PMcL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 545,
     "status": "ok",
     "timestamp": 1606221138939,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "da4v8xdQPVWv"
   },
   "outputs": [],
   "source": [
    "number_of_features=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6511,
     "status": "ok",
     "timestamp": 1606221163927,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "aVYHp0j1PYlG",
    "outputId": "d66d7fab-6da3-4f0b-804e-f8e28c7b4a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test,y_test)=imdb.load_data(num_words=number_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 1853,
     "status": "ok",
     "timestamp": 1606221196055,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "fP9CUqzpPdPk"
   },
   "outputs": [],
   "source": [
    "# 각 샘플이 400개의 특성을 가지도록 패딩하거나 잘라냄\n",
    "\n",
    "features_train=sequence.pad_sequences(x_train, maxlen=400)\n",
    "features_test=sequence.pad_sequences(x_test, maxlen=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "executionInfo": {
     "elapsed": 764,
     "status": "error",
     "timestamp": 1606221653297,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "YOSVtwvVPmOW",
    "outputId": "37882361-6ffe-440f-9ad2-16210f790bad"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1811\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1812\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1813\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape must be at least rank 3 but is rank 2 for '{{node BiasAdd}} = BiasAdd[T=DT_FLOAT, data_format=\"NCHW\"](add, bias)' with input shapes: [?,512], [512].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-cbbf8cb3c89c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber_of_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# 임베딩 층 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# 128개의 유닛을 가진 LSTM 층을 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    219\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1115\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m               \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m   1181\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m         (last_output, outputs, new_h, new_c,\n\u001b[0;32m-> 1183\u001b[0;31m          runtime) = lstm_with_backend_selection(**normal_lstm_kwargs)\n\u001b[0m\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m       \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mlstm_with_backend_selection\u001b[0;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   1556\u001b[0m   \u001b[0;31m# grappler will kick in during session execution to optimize the graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m   last_output, outputs, new_h, new_c, runtime = defun_standard_lstm(\n\u001b[0;32m-> 1558\u001b[0;31m       **params)\n\u001b[0m\u001b[1;32m   1559\u001b[0m   \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_gpu_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2828\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mstandard_lstm\u001b[0;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   1313\u001b[0m       input_length=(sequence_lengths\n\u001b[1;32m   1314\u001b[0m                     if sequence_lengths is not None else timesteps),\n\u001b[0;32m-> 1315\u001b[0;31m       zero_output_for_mask=zero_output_for_mask)\n\u001b[0m\u001b[1;32m   1316\u001b[0m   return (last_output, outputs, new_states[0], new_states[1],\n\u001b[1;32m   1317\u001b[0m           _runtime(_RUNTIME_CPU))\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   4212\u001b[0m     \u001b[0;31m# the value is discarded.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4213\u001b[0m     output_time_zero, _ = step_function(\n\u001b[0;32m-> 4214\u001b[0;31m         input_time_zero, tuple(initial_states) + tuple(constants))\n\u001b[0m\u001b[1;32m   4215\u001b[0m     output_ta = tuple(\n\u001b[1;32m   4216\u001b[0m         tensor_array_ops.TensorArray(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(cell_inputs, cell_states)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_tm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurrent_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[0mz0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(x, bias, data_format)\u001b[0m\n\u001b[1;32m   5770\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5771\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5772\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NCHW'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5773\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NHWC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5774\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(value, bias, data_format, name)\u001b[0m\n\u001b[1;32m   3365\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3366\u001b[0m       return gen_nn_ops.bias_add(\n\u001b[0;32m-> 3367\u001b[0;31m           value, bias, data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m   3368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(value, bias, data_format, name)\u001b[0m\n\u001b[1;32m    692\u001b[0m   \u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m--> 694\u001b[0;31m         \"BiasAdd\", value=value, bias=bias, data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m    695\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    742\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    743\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    591\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    592\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3483\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3484\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3485\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3486\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3487\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1974\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0;32m-> 1975\u001b[0;31m                                 control_input_ops, op_def)\n\u001b[0m\u001b[1;32m   1976\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1977\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1813\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1815\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be at least rank 3 but is rank 2 for '{{node BiasAdd}} = BiasAdd[T=DT_FLOAT, data_format=\"NCHW\"](add, bias)' with input shapes: [?,512], [512]."
     ]
    }
   ],
   "source": [
    "network=models.Sequential()\n",
    "\n",
    "network.add(layers.Embedding(input_dim=number_of_features, output_dim=128))   # 임베딩 층 추가\n",
    "network.add(layers.LSTM(units=128))   # 128개의 유닛을 가진 LSTM 층을 추가\n",
    "network.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "network.compile(loss='binary_crossentropy',\n",
    "                optimizer='Adam',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0vRcB9-QQC-Z"
   },
   "outputs": [],
   "source": [
    "history=network.fit(features_train,\n",
    "                    target_train,\n",
    "                    epochs=3,\n",
    "                    verbose=0,\n",
    "                    batch_size=1000,\n",
    "                    validation_data=(features_test, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "executionInfo": {
     "elapsed": 742,
     "status": "error",
     "timestamp": 1606221870026,
     "user": {
      "displayName": "강의현",
      "photoUrl": "",
      "userId": "04564851941527634728"
     },
     "user_tz": -540
    },
    "id": "mgf09j5DRZ0q",
    "outputId": "fa463e56-1052-4f94-cc1d-b6b29d8c33c7"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1811\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1812\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1813\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape must be at least rank 3 but is rank 2 for '{{node BiasAdd}} = BiasAdd[T=DT_FLOAT, data_format=\"NCHW\"](MatMul, unstack)' with input shapes: [?,384], [384].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-57787ee1ae55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    219\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1115\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m               \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m       last_output, outputs, runtime, states = self._defun_gru_call(\n\u001b[0;32m--> 441\u001b[0;31m           inputs, initial_state, training, mask, row_lengths)\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36m_defun_gru_call\u001b[0;34m(self, inputs, initial_state, training, mask, sequence_lengths)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m       last_output, outputs, new_h, runtime = gru_with_backend_selection(\n\u001b[0;32m--> 501\u001b[0;31m           **normal_gru_kwargs)\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mgru_with_backend_selection\u001b[0;34m(inputs, init_h, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001b[0m\n\u001b[1;32m    782\u001b[0m   \u001b[0;31m# Call the normal GRU impl and register the CuDNN impl function. The\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m   \u001b[0;31m# grappler will kick in during session execution to optimize the graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m   \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefun_standard_gru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m   \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_gpu_gru\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2828\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mstandard_gru\u001b[0;34m(inputs, init_h, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001b[0m\n\u001b[1;32m    583\u001b[0m       \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_lengths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0msequence_lengths\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m       zero_output_for_mask=zero_output_for_mask)\n\u001b[0m\u001b[1;32m    586\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_runtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_RUNTIME_CPU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   4212\u001b[0m     \u001b[0;31m# the value is discarded.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4213\u001b[0m     output_time_zero, _ = step_function(\n\u001b[0;32m-> 4214\u001b[0;31m         input_time_zero, tuple(initial_states) + tuple(constants))\n\u001b[0m\u001b[1;32m   4215\u001b[0m     output_ta = tuple(\n\u001b[1;32m   4216\u001b[0m         tensor_array_ops.TensorArray(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(cell_inputs, cell_states)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;31m# inputs projected by all gate matrices at once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0mmatrix_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m     \u001b[0mmatrix_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0mx_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(x, bias, data_format)\u001b[0m\n\u001b[1;32m   5770\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5771\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5772\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NCHW'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5773\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NHWC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5774\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(value, bias, data_format, name)\u001b[0m\n\u001b[1;32m   3365\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3366\u001b[0m       return gen_nn_ops.bias_add(\n\u001b[0;32m-> 3367\u001b[0;31m           value, bias, data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m   3368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(value, bias, data_format, name)\u001b[0m\n\u001b[1;32m    692\u001b[0m   \u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m--> 694\u001b[0;31m         \"BiasAdd\", value=value, bias=bias, data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m    695\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    742\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    743\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    591\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    592\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3483\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3484\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3485\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3486\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3487\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1974\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0;32m-> 1975\u001b[0;31m                                 control_input_ops, op_def)\n\u001b[0m\u001b[1;32m   1976\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1977\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1813\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1815\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be at least rank 3 but is rank 2 for '{{node BiasAdd}} = BiasAdd[T=DT_FLOAT, data_format=\"NCHW\"](MatMul, unstack)' with input shapes: [?,384], [384]."
     ]
    }
   ],
   "source": [
    "# GRU\n",
    "\n",
    "network=models.Sequential()\n",
    "network.add(layers.Embedding(input_dim=100, output_dim=128))\n",
    "network.add(layers.GRU(units=128))\n",
    "network.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "network.compile(loss='binary_crossentropy',\n",
    "                ooptimizer='Adam',\n",
    "                metrics=['Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c20ZmyRnSG67"
   },
   "outputs": [],
   "source": [
    "history=network.fit(features_train,\n",
    "                    target_train,\n",
    "                    epochs=3,\n",
    "                    verbose=1,\n",
    "                    batch_size=1000,\n",
    "                    validation_data=(features_test, target_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN0IO5WuYL4gKyHL7T5vNrZ",
   "collapsed_sections": [],
   "name": "ch20_신경망.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
