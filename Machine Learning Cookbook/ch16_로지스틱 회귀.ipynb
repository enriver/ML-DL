{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이진 분류기 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 로드하고 두 개의 클래스만 선택\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "X=iris.data[:100,:]\n",
    "y=iris.target[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 표준화\n",
    "\n",
    "standardizer=StandardScaler()\n",
    "X_std=standardizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 회귀모델 생성\n",
    "\n",
    "logit=LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "\n",
    "model=logit.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이름이 '회귀'이지만 로지스틱 회귀는 사실 널리 사용되는 이진 분류기이다.\n",
    "\n",
    "로지스틱 회귀에서 선형 모델은 로지스틱 함수에 포함된다.\n",
    "\n",
    "로지스틱 함수는 함수의 출력을 0과 1사이로 제한하는 효과가 있다. 0.5보다 크면 1, 0.5 보다 작으면 0으로 예측한다.\n",
    "\n",
    "사이킷런에서 LogisticRegression 클래스를 사용해 로지스틱 회귀 모델을 훈련할 수 있다.\n",
    "\n",
    "훈련이 끝나면 이 모델을 사용해 새로운 샘플의 클래스를 예측할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 샘플 생성\n",
    "\n",
    "new_observation=[[.5, .5, .5, .5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 예측\n",
    "\n",
    "model.predict(new_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99456551, 0.00543449]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 에측 확률도 볼 수 있다.\n",
    "\n",
    "model.predict_proba(new_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0 클래스에 속할 확률 : 99.46 %\n",
    "- 1 클래스에 속할 확률 : 0.54 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다중 클래스 분류기 훈련하기\n",
    "### OVR 또는 다중 분류 기법으로 사이킷런의 LogisticRegression 을 사용해 로지스틱 회귀를 훈련한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터로드\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "X=iris.data\n",
    "y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 표준화\n",
    "\n",
    "standardizer=StandardScaler()\n",
    "X_std=standardizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OVR 로지스틱 회귀 모델을 만든다.\n",
    "\n",
    "logit_ovr=LogisticRegression(random_state=0, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "\n",
    "model=logit_ovr.fit(X_std, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로지스틱 회귀 자체는 이진 분류기이다. 하지만 두 가지 방식으로 로지스틱 회귀를 확장하여 처리할 수 있다.\n",
    "\n",
    "1. OVR 로지스틱 회귀는 클래스마다 모델을 만든다. 개별 모델은 샘플이 해당 클레스에 속하는지 측정한다. (즉 이진분류 모델이 된다)\n",
    "2. 로지스틱 함수를 소프트맥스 함수로 바꿈으로써 다항 로지스틱 회귀를 구현할 수 있다.\n",
    "\n",
    "MLR (다중 로지스틱 회귀)의 장점은 predict_proba 메소드를 사용해 예측한 확률을 더 신뢰할 수 있다는 것이다.\n",
    "\n",
    "***\n",
    "LogisticRegression 을 사용할 때 두 가지 기법 중 하나를 사용할 수 있다.\n",
    "\n",
    "기본값은 OVR 을 의미하는 ovr 이다. 매개변수값을 multinomial로 지정해 MLR로 바꿀 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 규제로 분산 줄이기\n",
    "### 규제 강도를 조절하는 하이퍼 파라미터 C를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터로드\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "X=iris.data\n",
    "y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 표준화\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_std=scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 회귀모델 생성\n",
    "\n",
    "logit_regression=LogisticRegressionCV(penalty='l2',#릿지\n",
    "                                     Cs=10, # 탐색할 C의 범위(실수 리스트를 매개변수로 입력,\n",
    "                                    #정수를 입력하면 -10000~10000 사이에서 로그 스케일로 정수만큼의 후보 값의 리스트 생성 np.logspace)\n",
    "                                     random_state=0,\n",
    "                                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "\n",
    "model=logit_regression.fit(X_std,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "규제는 복잡한 모델에 패널티를 가해 분산을 줄이는 방법이다.\n",
    "\n",
    "구체적으로 최소화하려는 손실 함수에 패널티 항을 추가한다. 전형적으로 L1, L2 패널티를 사용한다.\n",
    "\n",
    "***\n",
    "로지스틱 회귀를 사용할 때 분산을 낮추려면 C를 하이퍼파라미터로 생각하고 최선의 모델을 만드는 C의 값을 찾야아한다.\n",
    "\n",
    "사이킷런의 LogisticRegressionCV 을 사용하면 효율적으로 C 값을 튜닝할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.5443469, 21.5443469, 21.5443469])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LogisticRegressionCV 가 찾은 각 클래스별 최적의 C값은 C_ 속성에 저장되어 있다.\n",
    "\n",
    "logit_regression.C_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression 과 LogisticRegressionCV 클래스에서 solver='saga' 일 때\n",
    "\n",
    "penalty='elasticnet' 로 지정하고 l1_ratio 를 조정하여 엘라스틱 넷의 L1 페널티의 양을 제어할 수 있다.\n",
    "***\n",
    "l1_ratio=1 은 penalty='l1' 과 같고, l1_ratio=0 은 penalty='l2' 와 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 대용량 데이터에서 분류기 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터로드\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "X=iris.data\n",
    "y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 표준화\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_std=scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 회귀모델 생성\n",
    "\n",
    "logit=LogisticRegression(random_state=0, solver='sag') # SAG= Stochastic Average Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "\n",
    "model=logit.fit(X_std, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런의 LogisticRegression 클래스는 solver 매개변수에서 여러가지 로지스틱 회귀 훈련 기법을 지원한다.\n",
    "\n",
    "대부분 사이킷런은 최선의 방법을 자동으로 선택하거나 해당 방법으로 처리할 수 없을 때 경고를 발생시킨다.\n",
    "\n",
    "***\n",
    "#### 데이터셋이 매우 클 때는 확률적 평균 경사 하강법이 다른 방법보다 훨씬 빠르게 모델을 훈련하 ㄹ수 있다.\n",
    "\n",
    "이 방법은 특성의 스케일에 매우 민감하기 때문에 특성의 표준화가 매우 중요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "penalty='none' is not supported for the liblinear solver",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-e270079b0e5b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 에러 발생 코드\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'liblinear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'none'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_std\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1486\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mSAGA\u001b[0m \u001b[0msolver\u001b[0m \u001b[0msupports\u001b[0m \u001b[0mboth\u001b[0m \u001b[0mfloat64\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfloat32\u001b[0m \u001b[0mbit\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1487\u001b[0m         \"\"\"\n\u001b[1;32m-> 1488\u001b[1;33m         \u001b[0msolver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_solver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1490\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_check_solver\u001b[1;34m(solver, penalty, dual)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'liblinear'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpenalty\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'none'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m         raise ValueError(\n\u001b[1;32m--> 456\u001b[1;33m             \u001b[1;34m\"penalty='none' is not supported for the liblinear solver\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    457\u001b[0m         )\n\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: penalty='none' is not supported for the liblinear solver"
     ]
    }
   ],
   "source": [
    "# 에러 발생 코드\n",
    "\n",
    "LogisticRegression(random_state=0, solver='liblinear', penalty='none').fit(X_std,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solver='liblinear' 와 penalty='none' 은 양립할 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-330e8687e308>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 에러 발생 코드 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sag'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_std\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1486\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mSAGA\u001b[0m \u001b[0msolver\u001b[0m \u001b[0msupports\u001b[0m \u001b[0mboth\u001b[0m \u001b[0mfloat64\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfloat32\u001b[0m \u001b[0mbit\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1487\u001b[0m         \"\"\"\n\u001b[1;32m-> 1488\u001b[1;33m         \u001b[0msolver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_solver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1490\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_check_solver\u001b[1;34m(solver, penalty, dual)\u001b[0m\n\u001b[0;32m    443\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'liblinear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'saga'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpenalty\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'l2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'none'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m         raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n\u001b[1;32m--> 445\u001b[1;33m                          \"got %s penalty.\" % (solver, penalty))\n\u001b[0m\u001b[0;32m    446\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'liblinear'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdual\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m         raise ValueError(\"Solver %s supports only \"\n",
      "\u001b[1;31mValueError\u001b[0m: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty."
     ]
    }
   ],
   "source": [
    "# 에러 발생 코드 2\n",
    "\n",
    "LogisticRegression(random_state=0, solver='sag', penalty='l1').fit(X_std,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solver='sag' 는 penalty='l1'을 지원하지 않고, penalty=['l2','none'] 을 지원한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 불균형한 클래스 다루기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "X=iris.data\n",
    "y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음 40 개 샘플을 제거하여 불균형한 클래스생성\n",
    "\n",
    "X=X[40:,:]\n",
    "y=y[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타깃 벡터에서 0이 아닌 클래스는 모두 1로 만든다.\n",
    "\n",
    "y=np.where((y==0),0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 표준화\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_std=scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 회귀 모델 생성\n",
    "\n",
    "logit_regression=LogisticRegression(random_state=0, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "\n",
    "model=logit_regression.fit(X_std, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런에 있는 다른 학습 알고리즘들처럼  LogisticRegression 은 자체적으로 불균형한 클래스르 다룰 수 있다.\n",
    "\n",
    "불균형한 클래스를 전처리 과정중에서 처리하지 못했다면 **class_weight** 매개변수로 클래스에 가중치를 부여하여\n",
    "균형잡힌 클래스를 만들 수 있다. 'balanced' 로 지정하면 자동으로 클래스 빈도의 **역수로 가중치를 부여**한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class_weight=\"balanced\" 로 설정했을 때 로지스틱 모델이 계산한 클래스 가중치는\n",
    "\n",
    "compute_class_weight 함수를 사용하여 구할 수 있다.\n",
    "'''\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.5 , 0.55])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 레이블이 0, 1인 데이터의 클래스 가중치 계산\n",
    "\n",
    "compute_class_weight('balanced',[0,1],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 역수로 가중치가 부여됐음을 확인할 수 있다\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class_weight 매개변수에 {클래스_레이블 : 가중치} 형식의 딕셔너리를 전달할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10:1 의 클래스 가중치를 부여한 로지스틱 회귀 모델 생성\n",
    "\n",
    "logistic_regression=LogisticRegression(random_state=0, class_weight={0:10, 1:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "\n",
    "moel=logistic_regression.fit(X_std,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 샘플 생성\n",
    "\n",
    "new_observation=[[.5,.5,.5,.5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00160721, 0.99839279]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측값 확인\n",
    "\n",
    "model.predict_proba(new_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(new_observation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
