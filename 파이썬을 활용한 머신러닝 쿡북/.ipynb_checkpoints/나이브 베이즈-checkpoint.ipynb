{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "베이즈(Bayes) 이론은 새로운 정보 P(B|A)와 사건의 사전확률 P(A) 가 주어졌을 때 어떤 사건이 일어날 확률을 이해하는 방법이다.\n",
    "\n",
    "***\n",
    "P(A|B)=P(B|A)*P(A) / P(B)\n",
    "***\n",
    "\n",
    "나이브 베이즈 분류기는 머신러닝에서 베이즈 이론을 분류기에 적용한 것이며,\n",
    "\n",
    "실용적인 머신러닝에서 필요한 다음과 같은 기능을 하나의 분류기에서 제공한다.   \n",
    "\n",
    "1. 직관적인 방법을 사용한다\n",
    "2. 작은 양의 데이터에서 사용할 수 있다\n",
    "3. 훈련과 예측에 계산 비용이 적게 든다\n",
    "4. 환경이 바뀌더라도 자주 안정적인 결과를 만든다.\n",
    "\n",
    "***\n",
    "\n",
    "나이브 베이즈 분류기를 사용할 때\n",
    "\n",
    "1. 데이터에 있는 각 특성에 대해 가능도의 통계적 분포 P(Xi|Y) 를 가정해야 한다. 정규분포(가우시안 분포), 다항분포, 베르누이 분포를 자주 사용한다. <br> 종종 특성의 성질(연속, 이진 등)에 따라 분포를 선택한다.\n",
    "\n",
    "2. 각 특성과 특성의 가능도가 독립적이라고 가정하기 때문에 나이브 베이즈라고 부른다. 이러한 '나이브' 한 가정은 잘못된 경우가 많지만 실제 높은 품질의 분류기를 만드는 데 방해가 되지는 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연속적인 특성으로 분류기 훈련하기\n",
    "### 연속적인 특성만 있을 때 가우시안 나이브 베이즈 분류기를 사용하는 법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 \n",
    "\n",
    "iris=datasets.load_iris()\n",
    "X=iris.data\n",
    "y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가우시안 나이브 베이즈 객체 생성\n",
    "\n",
    "classifier=GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "\n",
    "model=classifier.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 샘플 생성\n",
    "\n",
    "new_observation=[[4,4,4,0.4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 예측\n",
    "\n",
    "model.predict(new_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나이브 베이즈 분류기의 흥미로운 점 중 하나는 타깃 클래스에 대한 사전 확률을 지정할 수 있다는 것이다.\n",
    "\n",
    "GaussianNB 클래스의 priors 매개변수를 사용하여 타깃 벡터의 각 클래스에 할당할 확률 리스트를 전달할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=GaussianNB(priors=[0.25,0.25,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "\n",
    "model=clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "priors 매개변수에 값을 지정하지 않으면 데이터를 기반으로 사전 확률을 계산한다.\n",
    "\n",
    "predict_proba 메소드에서 출력되는 가우시안 나이브 베이즈의 예측 확률은 **보정되어 있지 않다(= 신뢰할만 하지 않다)**\n",
    "\n",
    "쓸만한 예측 확률을 얻으려면 등위회귀나, 관련된 다른 방법을 사용해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이산적인 카운트 특성으로 분류기 훈련하기\n",
    "### 다항(multinomial) 나이브 베이즈 분류기 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 생성\n",
    "\n",
    "text_data=np.array(['I love Korea. Korea!',\n",
    "                   'Korea is best',\n",
    "                   'France beats both'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW(Bag of Words) 를 만든다.\n",
    "\n",
    "count=CountVectorizer()\n",
    "bag_of_words=count.fit_transform(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성행렬 생성\n",
    "\n",
    "features=bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타깃 벡터 생성\n",
    "\n",
    "target=np.array([0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 클래스별 사전 확률을 지정한 다항 나이브 베이즈 객체 생성\n",
    "\n",
    "classifier=MultinomialNB(class_prior=[0.25,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "\n",
    "model=classifier.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다항 나이브 베이즈는 가우시안 나이브 베이즈와 비슷하게 작동하지만 특성이 다항 분포라고 가정한다.\n",
    "\n",
    "다항 나이브 베이즈가 가장 많이 사용되는 경우 중 하나는 BoW(Bag of words)나 tf-idf 방식을 사용한 텍스트 분류이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 샘플 생성\n",
    "\n",
    "new_observation=[[0,0,0,1,0,1,0]]\n",
    "\n",
    "# 새로운 샘플의 클래스 예측\n",
    "\n",
    "model.predict(new_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class_prior 가 지정되지 않으면 데이터를 사용하여 사전 확률을 학습한다.\n",
    "\n",
    "사전 확률로 균등 분포를 사용하려면 fit_prior=False 로 지정한다.\n",
    "\n",
    "추가적으로 MultinomialNB 는 평탄화(smoothing) 매개변수 alpha가 있으며 튜닝해야한다.\n",
    "\n",
    "기본값은 1.0 이고, 0.0 이면 평탄화가 없다는 것을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이진 특성으로 나이브 베이즈 분류기 훈련하기\n",
    "### 베르누이 나이브 베이즈 분류기를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1],\n",
       "       [0, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 세 개의 이진 특성 만들기\n",
    "\n",
    "features=np.random.randint(2, size=(100,3))\n",
    "features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이진 타깃 벡터 생성\n",
    "\n",
    "target=np.random.randint(2,size=(100,1)).ravel()   # ravel -> 1차원 배열로 바꾸어줌\n",
    "target[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 클래스별 사전 확률을 지정하여 베르누이 나이브 베이즈 객체 생성\n",
    "\n",
    "classifier=BernoulliNB(class_prior=[0.25,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "\n",
    "model=classifier.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "베르누이 나이브 베이즈 분류기는 모든 특성이 두 종류의 값만 발생할 수 있는 이진 특성이라고 가정한다. (ex : 원핫 인코딩된 순서가 없는 범주형 특성)\n",
    "\n",
    "다항 나이브 베이즈와 비슷하게 베르누이 나이브 베이즈는 텍스트 분류에 많이 사용된다.\n",
    "\n",
    "이런 특성 행렬은 한 문서에 어떤 단어가 등장하는지 여부를 담고 있다.\n",
    "\n",
    "사전 확률을 지정하려면 class_prior 매개변수에 클래스별 사전 확률을 담은 리스트를 전달한다.\n",
    "\n",
    "균등 분포를 사용하려면 fit_prior=False 로 지정한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uniform_prior=BernoulliNB(class_prior=None, fit_prior=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측 확률 보정하기\n",
    "### 나이브 베이즈 분류기의 예측 확률을 이해하기 쉽도록 보정하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터로드\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "X=iris.data\n",
    "y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가우시안 나이브 베이즈 객체 생성\n",
    "\n",
    "classifier=GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시그모이드 보정을 사용해 보정 교차 검증 생성\n",
    "\n",
    "classifier_sigmoid=CalibratedClassifierCV(classifier, cv=2, method='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=GaussianNB(priors=None,\n",
       "                                                 var_smoothing=1e-09),\n",
       "                       cv=2, method='sigmoid')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 확률 보정\n",
    "\n",
    "classifier_sigmoid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 샘플 생성\n",
    "\n",
    "new_observation=[[2.6, 2.6, 2.6, 0.4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31859969, 0.63663466, 0.04476565]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 보정된 확률 확인\n",
    "\n",
    "classifier_sigmoid.predict_proba(new_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나이브 베이즈 분류기를 포함한 일부 모델은 실전과 맞지 않는 확률을 반환한다.\n",
    "\n",
    "특히 나이브 베이즈에서는 타깃 클래스에 대한 예측 확률의 순위는 유효하지만 예측 확률이 0 또는 1 에 극단적으로 가까워지는 경향이 있다.\n",
    "\n",
    "***\n",
    "\n",
    "의미있는 예측 확률을 얻으려면 보정(Calibration) 이라 부르는 작업을 수행해야 한다.\n",
    "\n",
    "사이킷런에서 CalibratedClassifierCV 클래스를 사용하여 잘 보정된 예측 확률을 K-폴드 교차검증으로 만들 수 있다.\n",
    "\n",
    "CalibratedClassifierCV 에서 훈련 세트를 사용해 모델을 훈련하고 테스트 세트를 사용해 예측 확률을 보정한다.\n",
    "\n",
    "반환된 예측 확률은 k-폴드의 평균이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.31548432e-04, 9.99768128e-01, 3.23532277e-07]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가우시안 나이브 베이즈를 훈련하고 클래스 확률 예측\n",
    "\n",
    "classifier.fit(X,y).predict_proba(new_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31859969, 0.63663466, 0.04476565]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 보정된 확률 결과\n",
    "\n",
    "classifier_sigmoid.predict_proba(new_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CalibratedClassifierCV 는 method 매개변수에서 아래의 두 개의 보정 방법을 지원한다.\n",
    "\n",
    "- 플랫(platt) 의 시그모이드 모델\n",
    "- 등위회귀\n",
    "\n",
    "등위회귀는 비모수 모델이기 때문에 샘플 크기가 작으면 과대적합되는 경향이 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
