{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 샘플의 최근접 이웃 찾기\n",
    "### 가장 가까운 k개의 샘플에서 다수의 클래스를 그 샘플의 클래스로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "features=iris.data\n",
    "target=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준화 객체 생성\n",
    "\n",
    "scaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 표준화\n",
    "\n",
    "features_scaled=scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=2 인 최근접 이웃 모델 생성\n",
    "\n",
    "knn=NearestNeighbors(n_neighbors=2).fit(features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 샘플 생성\n",
    "\n",
    "new_observation=[1,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49140089 0.74294782]]\n",
      "[[124 110]]\n"
     ]
    }
   ],
   "source": [
    "# 이 샘플과 가장 가까운 이웃의 인덱스와 거리 찾기\n",
    "\n",
    "distances, indices= knn.kneighbors([new_observation])\n",
    "print(distances)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.03800476, 0.55861082, 1.10378283, 1.18556721],\n",
       "        [0.79566902, 0.32841405, 0.76275827, 1.05393502]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최근접 이웃 확인\n",
    "\n",
    "features_scaled[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN 의 거리측정에는 다양한 방법을 제공한다.\n",
    "\n",
    "기본값으로는 민코우스키 거리 방식을 제공한다. 민코우스키 거리에는 하이퍼파라미터 p가 있다.\n",
    "\n",
    "p=1 일때, 맨해튼 거리이고 p=2 일때, 유클리드 거리이다. 사이킷런의 기본값은 p=2 (유클리드) 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric 을 사용하여 거리 측정 방법을 지정할 수 있다.\n",
    "\n",
    "nn_euclidean=NearestNeighbors(n_neighbors=2, metric='euclidean').fit(features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' kneighbors_graph 메소드를 사용하여 샘플의 최근접 이웃을 나타내는 행렬을 만들 수 있다.'''\n",
    "\n",
    "nn_euclidean=NearestNeighbors(n_neighbors=3, metric='euclidean').fit(features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 샘플의 (자기 자신을 포함한) 3개의 최근집 이웃을 나타내는 리스트의 행렬\n",
    "\n",
    "nn_with_self=nn_euclidean.kneighbors_graph(features_scaled).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최근접 이웃중에서 1로 표시된 자기 자신 제외\n",
    "\n",
    "for i,x in enumerate(nn_with_self):\n",
    "    x[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 번째 샘플에 대한 두 개의 최근접 이웃 확인\n",
    "\n",
    "nn_with_self[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최근접 이웃을 찾거나 거리 기반의 학습 알고리즘을 사용할 때 특성을 같은 스케일을 갖도록 변환하는 것이 중요하다.\n",
    "\n",
    "이런 이유는 거리 측정 방법이 모든 특성을 같은 스케일로 다루기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' kneighbors 메소드에서 n_neighbors 매개변수를 다르게 지정할 수 있고,\n",
    "return_distance 를 False로 지정하면 최근접 이웃의 인덱스만 반환한다'''\n",
    "\n",
    "indices=knn.kneighbors([new_observation], n_neighbors=5, return_distance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.03800476, 0.55861082, 1.10378283, 1.18556721],\n",
       "        [0.79566902, 0.32841405, 0.76275827, 1.05393502],\n",
       "        [0.4321654 , 0.78880759, 0.93327055, 1.44883158],\n",
       "        [0.55333328, 0.78880759, 1.0469454 , 1.58046376],\n",
       "        [1.03800476, 0.55861082, 1.10378283, 1.71209594]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최근접 이웃 확인\n",
    "\n",
    "features_scaled[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "radius_neighbors 메소드는 주어진 반경 내의 이웃을 모두 찾아준다.\n",
    "\n",
    "반경은 NearestNeighbors 클래스의 radius 에서 지정할 수 있다. 기본값은 1.0 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반경 0.5 안에 있는 모든 샘플의 인덱스를 찾는다.\n",
    "\n",
    "indices=knn.radius_neighbors([new_observation], radius=0.5, return_distance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.03800476, 0.55861082, 1.10378283, 1.18556721]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 반경 내의 이웃확인\n",
    "\n",
    "features_scaled[indices[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kneighbors_graph 메소드와 마찬가지로 radius_neighbors_graph를 사용하여 반경 내의 이웃을 나타내는 행렬을 만들 수 있다.\n",
    "\n",
    "이 메소드도 희소행렬을 반환하기 때문에 toarray 메소드를 사용하여 밀집 배열로 바꾼다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반경 내의 이웃을 나타내는 리스트의 행렬\n",
    "\n",
    "nn_with_self=knn.radius_neighbors_graph([new_observation], radius=0.5).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 샘플에 대한 반경 내의 이웃 확인\n",
    "\n",
    "nn_with_self[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-최근접 이웃 분류기 만들기\n",
    "### 클래스를 모르는 샘플이 주어졌을 때 이웃한 샘플의 클래스를 기반으로 이 샘플의 클래스 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋이 아주 크지 않다면 KNeighborsClassifier 사용\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터로드\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "X=iris.data\n",
    "y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준화 객체 생성\n",
    "\n",
    "standardizer=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 표준화\n",
    "\n",
    "X_std=standardizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5개의 이웃을 사용한 KNN 분류기 훈련\n",
    "\n",
    "knn=KNeighborsClassifier(n_neighbors=5, n_jobs=-1).fit(X_std, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두개의 샘플 생성\n",
    "\n",
    "new_observations=[[0.75, 0.75, 0.75, 0.75],\n",
    "                 [1, 1, 1, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두 샘플의 클래스 예측\n",
    "\n",
    "knn.predict(new_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.6, 0.4],\n",
       "       [0. , 0. , 1. ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 샘플이 세 클래스에 속할 확률 확인\n",
    "\n",
    "knn.predict_proba(new_observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier 에는 중요한 매개변수가 많이 있다.\n",
    "\n",
    "\n",
    "- metric : 사용할 거리 측정 방법을 지정\n",
    "- n_jobs : 얼마나 많은 컴퓨터 코어를 사용할지 결정\n",
    "- algorithm : 가장 가까운 이웃을 계산하기 위한 방법 지정(알고리즘마다 차이가 있지만 KNeighborsClassifier 는 자동으로 최선의 알고리즘을 찾음)\n",
    "- weights : 값을 distances 로 지정하면 멀리떨어진 샘플보다 가까운 이웃의 투표에 가중치가 더 부여된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀문제에는 KNeighborsRegressor 클래스를 사용할 수 있다.\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 로드\n",
    "\n",
    "boston=datasets.load_boston()\n",
    "X=boston.data[:,0:2]\n",
    "y=boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최근접 회귀모델 생성\n",
    "\n",
    "knn_regressor=KNeighborsRegressor(n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "\n",
    "model=knn_regressor.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32440.000000000004"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 샘플의 타깃값을 예측하고 1000을 곱한다\n",
    "\n",
    "model.predict(X)[0]*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32440.000000000004"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 샘플에 대한 이웃의 타깃값을 평균하여 predict 메소드와 결과 비교\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "indices=model.kneighbors(X[0:1], return_distance=False)\n",
    "np.mean(y[indices])*1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최선의 이웃 개수 결정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터로드\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "X=iris.data\n",
    "y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  표준화객체 생성\n",
    "\n",
    "standardizer=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN 분류기 생성\n",
    "\n",
    "knn=KNeighborsClassifier(n_neighbors=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인 생성\n",
    "\n",
    "pipe=Pipeline([(\"standardizer\",standardizer),(\"knn\",knn)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 탐색 영역 후보 생성\n",
    "\n",
    "search_space=[{\"knn__n_neighbors\":[1,2,3,4,5,6,7,8,9,10]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    3.0s finished\n"
     ]
    }
   ],
   "source": [
    "# 그리드 서치 생성\n",
    "\n",
    "classifier=GridSearchCV(pipe, search_space, cv=5, verbose=1).fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k 값의 크기는 KNN 분류기에 큰 영향을 미친다.\n",
    "\n",
    "편햐과 분산 사이에 균형점을 찾아야하는 머신러닝에서 K 값만큼 명확한 경우가 많지 않다.\n",
    "\n",
    "n이 샘플의 개수 있때 k=n 이면 편향이 높고 분산이 낮다. k=1 이면 편향이 낮고 분산이 높다.\n",
    "\n",
    "이 편향-분산 트레이드오프의 균형을 맞추는 k값을 찾으면 최선의 모델을 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최선의 이웃 개수(k)\n",
    "\n",
    "classifier.best_estimator_.get_params()[\"knn__n_neighbors\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 반지름 기반의 최근접 이웃 분류기 만들기\n",
    "### 클래스를 모르는 샘플이 주어졌을 때 일정 거리 내의 모든 샘플의 클래스를 기반으로 이 샘플의 클래스 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터로드\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "X=iris.data\n",
    "y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준화객체\n",
    "\n",
    "standardizer=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 표준화\n",
    "\n",
    "X_std=standardizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반지름 이웃 분류기 훈련\n",
    "\n",
    "rnn=RadiusNeighborsClassifier(radius=0.5, n_jobs=-1).fit(X_std, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 샘플 생성\n",
    "\n",
    "new_observation=[[1,1,1,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 샘플의 클래스 예측\n",
    "\n",
    "rnn.predict(new_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN 분류에서 샘플의 클래스는 k개 이웃의 클래스로부터 예측된다.\n",
    "\n",
    "반지름 기반(RNN) 분류기는 이보다는 덜 사용되는 분류 방법이다.\n",
    "\n",
    "여기에서는 샘플의 클래스가 주어진 반지름  r 이내에 있는 모든 샘플의 클래스로부터 예측된다.\n",
    "\n",
    "사이킷런의 RadiusNeighborsClassifier 클래스는 두 개의 매개변수를 제외하고 KNeighborsClassifier 와 매우 비슷하다.\n",
    "\n",
    "\n",
    "첫번째로, RadiusNeighborsClassifier 는 radius 매개변수로 고정 영역의 반지름을 지정하여 이웃 샘플을 결정한다.\n",
    "radius 값을 지정할 확실한 근거가 있지 않다면 다른 하이퍼파라미터 처럼 모델 선택 과정으로 튜닝하는 것이 최선이다.\n",
    "\n",
    "두번째로 유용한 매개변수는 outlier_label 이다. 반지름 내에 다른 샘플이 하나도 없는 샘플에 부여할 레이블을 지정한다.\n",
    "\n",
    "이 기능을 이상치를 구별하는 데 종종 유용하게 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "outlier_label 의 기본값은 None 으로 이웃한 샘플을 찾지 못할 경우 예외를 발생시킨다.\n",
    "예외를 일으키는 대신 이상치로 표시하려면 일반적으로 클래스 레이블로 사용하지 않는 -1 을 지정할 수 있다.\n",
    "'''\n",
    "\n",
    "# 반지름 이웃 분류기 훈련\n",
    "\n",
    "rnn=RadiusNeighborsClassifier(radius=0.5, n_jobs=-1, outlier_label=-1).fit(X_std, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\river\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:566: UserWarning: Outlier label -1 is not in training classes. All class probabilities of outliers will be assigned with 0.\n",
      "  ''.format(self.outlier_label_[k]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.predict([[100,100,100,100]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
